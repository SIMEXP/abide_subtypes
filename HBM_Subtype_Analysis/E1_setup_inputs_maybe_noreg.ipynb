{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the model and the inputs for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Variable names\n",
    "regress_vars = ['AGE_AT_SCAN', 'FD_scrubbed']\n",
    "#regress_vars = ['FD_scrubbed']\n",
    "model_vars = ['SUB_ID', 'AGE_AT_SCAN', 'FD_scrubbed']\n",
    "group_var = 'DX_GROUP'\n",
    "nb_subtypes = 5\n",
    "procs = 7\n",
    "# 'ADOS_sb_sev', 'SRS_RAW_TOTAL'\n",
    "coi = 'DX_GROUP'\n",
    "scale = 7\n",
    "thing = 'full'\n",
    "\n",
    "model_name = 'model_{}_maybe_sc{}_noreg.csv'.format(thing, scale)\n",
    "mat_name = 'model_{}_maybe_sc{}_noreg.mat'.format(thing, scale)\n",
    "\n",
    "# Paths\n",
    "pheno_in = '/data1/guilimin/abide/pheno/merged_abide_{}_maybe.csv'.format(thing)\n",
    "\n",
    "local_root = '/data1/guilimin/abide/'\n",
    "#remote_root = '/home/surchs/sim_data/data/abide/'\n",
    "remote_root = local_root\n",
    "\n",
    "# Fixed stuff\n",
    "pipe_folder = os.path.join(remote_root, 'subtype/sc{}/{}_maybe_noreg/'.format(scale, thing))\n",
    "mask_path = os.path.join(remote_root, 'masks/template_mask.nii.gz')\n",
    "f_tmp = 'netstack_fmri_{:07}_session_{}_run{}.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = os.path.join(local_root, 'pheno', 'sc{}'.format(scale))\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not coi in model_vars:\n",
    "    model_vars.append(coi)\n",
    "if not group_var in model_vars:\n",
    "    model_vars.append(group_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno = pd.read_csv(pheno_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the input structure for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dict = dict()\n",
    "path_list = list()\n",
    "sub_list = list()\n",
    "pop_ind = list()\n",
    "for i, r in pheno.iterrows():\n",
    "    sub_name = 'sub_{}'.format(r.SUB_ID)\n",
    "    rel_path = os.path.join('sca_z', 'sc{}'.format(scale),\n",
    "                            f_tmp.format(r.SUB_ID,\n",
    "                                         r.session,\n",
    "                                         r.run))\n",
    "    \n",
    "    loc_path = os.path.join(local_root, rel_path)\n",
    "    rem_path = os.path.join(remote_root, rel_path)\n",
    "    # Check path locally\n",
    "    if not os.path.isfile(loc_path):\n",
    "        print('Something wrong with {}'.format(loc_path))\n",
    "        pop_ind.append(i)\n",
    "    else:\n",
    "        data_dict[sub_name] = rem_path\n",
    "        path_list.append(rem_path)\n",
    "        sub_list.append(sub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_array = np.array(path_list, dtype=object)\n",
    "sub_array = np.array(sub_list, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of those guys\n",
    "pheno.drop(pheno.index[pop_ind], inplace=True)\n",
    "# Make dummies for site\n",
    "dummies = pd.get_dummies(pheno['SITE_ID'], prefix='dummie')\n",
    "# Drop the first site again so we can add an intercept\n",
    "dummies.drop(dummies.columns[0], axis=1, inplace=True)\n",
    "# Get dummie names\n",
    "dummie_names = list(dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select and reorder the columns I need to run\n",
    "ordered_pheno = pheno[model_vars]\n",
    "# Add the dummie stuff to it\n",
    "model = pd.merge(ordered_pheno, dummies, left_index=True, right_index=True)\n",
    "# Add the dummies to the regressors\n",
    "regressors = regress_vars + dummie_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save it locally\n",
    "model.to_csv(os.path.join(model_dir, model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the files_in\n",
    "file_dict = dict()\n",
    "#file_dict['data'] = data_dict\n",
    "file_dict['mask'] = mask_path\n",
    "file_dict['model'] = os.path.join(remote_root, 'pheno', 'sc{}'.format(scale), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the opt\n",
    "opt_dict = dict()\n",
    "opt_dict['folder_out'] = pipe_folder\n",
    "opt_dict['scale'] = scale\n",
    "#opt_dict['stack'] = {'regress_conf': np.array(regressors,dtype=object), 'flag_conf':False}\n",
    "opt_dict['stack'] = {'flag_conf':False}\n",
    "opt_dict['subtype'] = {'nb_subtype':nb_subtypes, 'sub_map_type':'mean'}\n",
    "opt_dict['chi2'] = {'group_col_id':group_var}\n",
    "\n",
    "# Make the regressor thingee\n",
    "cont_dict = dict()\n",
    "#for regr in regressors:\n",
    "#    cont_dict[regr] = 0\n",
    "# Add the thing I am interested in \n",
    "cont_dict[coi] = 1\n",
    "\n",
    "# Add this\n",
    "opt_dict['association'] = {'contrast':cont_dict, 'fdr':0.05}\n",
    "# Set test to true\n",
    "opt_dict['flag_test'] = True\n",
    "# No figures, octave is too stupid for figures\n",
    "opt_dict['flag_visu'] = True\n",
    "opt_dict['flag_chi2'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up psom options\n",
    "psom_dict = dict()\n",
    "psom_dict['path_logs'] = os.path.join(pipe_folder, 'logs')\n",
    "psom_dict['max_queued'] = procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the whole shebang\n",
    "mat_dict = dict()\n",
    "mat_dict['files_in'] = file_dict\n",
    "mat_dict['opt'] = opt_dict\n",
    "mat_dict['opt_psom'] = psom_dict\n",
    "mat_dict['paths'] = path_array\n",
    "mat_dict['subs'] = sub_array\n",
    "sio.savemat(os.path.join(model_dir, mat_name), mat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
