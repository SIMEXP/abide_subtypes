{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the GLM on the Matlab stuff and see what I get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import io as sio\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#/data1/guilimin/abide/subtype/sc7/srs_maybe_ref_full_pruned_old/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#w_path = '/data1/guilimin/abide/subtype/sc12/full_maybe_old/sbt_weights_net_{}.csv'\n",
    "#m_path = '/data1/guilimin/abide/pheno/sc12/model_full_maybe_sc12.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_path = '/data1/guilimin/abide/subtype/sc7/full_maybe/sbt_weights_net_{}.csv'\n",
    "m_path = '/data1/guilimin/abide/pheno/sc7/model_full_maybe_sc7.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#w_path = '/data1/guilimin/abide/subtype/sc7/srs_maybe_ref_full_pruned/sbt_weights_net_{}.csv'\n",
    "#m_path = '/data1/guilimin/abide/pheno/sc7/model_srs_maybe_sc7_ref_full_pruned.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "cov = 'DX_GROUP'\n",
    "model = pd.read_csv(m_path)\n",
    "# Control = 0, ASD = 1\n",
    "model.DX_GROUP = (model.DX_GROUP-2)*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:11: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net 1 sbt 1 eff: 0.067, var: 0.004 p: 0.111 cohens: 0.134\n",
      "Net 1 sbt 2 eff: 0.148, var: 0.022 p: 0.000 cohens: 0.299\n",
      "Net 1 sbt 3 eff: 0.083, var: 0.007 p: 0.049 cohens: 0.166\n",
      "Net 1 sbt 4 eff: 0.001, var: 0.000 p: 0.978 cohens: 0.002\n",
      "Net 1 sbt 5 eff: 0.144, var: 0.021 p: 0.001 cohens: 0.292\n",
      "Net 2 sbt 1 eff: 0.083, var: 0.007 p: 0.048 cohens: 0.167\n",
      "Net 2 sbt 2 eff: 0.028, var: 0.001 p: 0.502 cohens: 0.056\n",
      "Net 2 sbt 3 eff: 0.045, var: 0.002 p: 0.284 cohens: 0.090\n",
      "Net 2 sbt 4 eff: 0.040, var: 0.002 p: 0.342 cohens: 0.080\n",
      "Net 2 sbt 5 eff: 0.212, var: 0.045 p: 0.000 cohens: 0.433\n",
      "Net 3 sbt 1 eff: 0.124, var: 0.015 p: 0.003 cohens: 0.249\n",
      "Net 3 sbt 2 eff: 0.118, var: 0.014 p: 0.005 cohens: 0.238\n",
      "Net 3 sbt 3 eff: 0.066, var: 0.004 p: 0.117 cohens: 0.132\n",
      "Net 3 sbt 4 eff: 0.090, var: 0.008 p: 0.033 cohens: 0.180\n",
      "Net 3 sbt 5 eff: 0.007, var: 0.000 p: 0.863 cohens: 0.014\n",
      "Net 4 sbt 1 eff: 0.064, var: 0.004 p: 0.130 cohens: 0.128\n",
      "Net 4 sbt 2 eff: 0.065, var: 0.004 p: 0.122 cohens: 0.130\n",
      "Net 4 sbt 3 eff: 0.042, var: 0.002 p: 0.317 cohens: 0.084\n",
      "Net 4 sbt 4 eff: 0.080, var: 0.006 p: 0.056 cohens: 0.161\n",
      "Net 4 sbt 5 eff: 0.000, var: 0.000 p: 0.995 cohens: 0.000\n",
      "Net 5 sbt 1 eff: 0.039, var: 0.002 p: 0.354 cohens: 0.078\n",
      "Net 5 sbt 2 eff: 0.013, var: 0.000 p: 0.757 cohens: 0.026\n",
      "Net 5 sbt 3 eff: 0.009, var: 0.000 p: 0.839 cohens: 0.017\n",
      "Net 5 sbt 4 eff: 0.056, var: 0.003 p: 0.186 cohens: 0.111\n",
      "Net 5 sbt 5 eff: 0.021, var: 0.000 p: 0.617 cohens: 0.042\n",
      "Net 6 sbt 1 eff: 0.119, var: 0.014 p: 0.005 cohens: 0.240\n",
      "Net 6 sbt 2 eff: 0.007, var: 0.000 p: 0.869 cohens: 0.014\n",
      "Net 6 sbt 3 eff: 0.047, var: 0.002 p: 0.265 cohens: 0.094\n",
      "Net 6 sbt 4 eff: 0.094, var: 0.009 p: 0.026 cohens: 0.188\n",
      "Net 6 sbt 5 eff: 0.132, var: 0.018 p: 0.002 cohens: 0.267\n",
      "Net 7 sbt 1 eff: 0.067, var: 0.004 p: 0.111 cohens: 0.134\n",
      "Net 7 sbt 2 eff: 0.012, var: 0.000 p: 0.784 cohens: 0.023\n",
      "Net 7 sbt 3 eff: 0.039, var: 0.002 p: 0.353 cohens: 0.078\n",
      "Net 7 sbt 4 eff: 0.061, var: 0.004 p: 0.148 cohens: 0.122\n",
      "Net 7 sbt 5 eff: 0.062, var: 0.004 p: 0.142 cohens: 0.124\n"
     ]
    }
   ],
   "source": [
    "scale = 7\n",
    "sbt = 5\n",
    "for net_id in np.arange(scale):\n",
    "    # Weights\n",
    "    weights = pd.read_csv(w_path.format(net_id+1))\n",
    "    # Give subject column a name\n",
    "    weights.rename(columns={' ':'SUB_ID'}, inplace=True)\n",
    "    # Drop whitespace \n",
    "    weights.columns = weights.columns.str.strip(' ')\n",
    "    # Get back to normal names\n",
    "    weights.SUB_ID = weights.SUB_ID.str.extract('(?<=sub_)(\\d+)').astype(int)\n",
    "    # Bring both of them together\n",
    "    merged = pd.merge(model, weights, on='SUB_ID', how='inner')\n",
    "    \n",
    "    for sbt_id in np.arange(sbt):\n",
    "        # Get the matrices\n",
    "        sbt_name = 'sub{}'.format(sbt_id+1)\n",
    "        y = merged[[sbt_name]]\n",
    "        x = merged[[cov]]\n",
    "        x['Intercept'] = np.ones(x.shape[0])\n",
    "        \n",
    "        m = sm.OLS(y, x)\n",
    "        results = m.fit()\n",
    "        \n",
    "        eff = np.sqrt(results.rsquared)\n",
    "        var = results.rsquared\n",
    "        pval = results.pvalues[cov]\n",
    "        \n",
    "        patients = merged[merged.DX_GROUP==1][sbt_name]\n",
    "        controls = merged[merged.DX_GROUP==0][sbt_name]\n",
    "        pat_std = np.std(patients)\n",
    "        ctr_std = np.std(controls)\n",
    "        n_pat = len(patients)\n",
    "        n_ctr = len(controls)\n",
    "        pooled_std = np.sqrt(((n_pat-1)*np.square(pat_std) + (n_ctr-1)*np.square(ctr_std))/(n_pat + n_ctr - 2))\n",
    "\n",
    "        cohensd = np.abs((np.mean(patients) - np.mean(controls)) / pooled_std)\n",
    "        \n",
    "        print('Net {} sbt {} eff: {:.3f}, var: {:.3f} p: {:.3f} cohens: {:.3f}'.format(net_id+1, sbt_id+1, eff, var, pval, cohensd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "investigate = ((1,5), (2,4), (3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look for motion\n",
    "for inv in investigate:\n",
    "    network, subtype = inv\n",
    "    # Weights\n",
    "    weights = pd.read_csv(w_path.format(network))\n",
    "    # Give subject column a name\n",
    "    weights.rename(columns={' ':'SUB_ID'}, inplace=True)\n",
    "    # Drop whitespace \n",
    "    weights.columns = weights.columns.str.strip(' ')\n",
    "    # Get back to normal names\n",
    "    weights.SUB_ID = weights.SUB_ID.str.extract('(?<=sub_)(\\d+)').astype(int)\n",
    "    # Bring both of them together\n",
    "    merged = pd.merge(model, weights, on='SUB_ID', how='inner')\n",
    "    \n",
    "    # Get the matrices\n",
    "    sbt_name = 'sub{}'.format(subtype)\n",
    "    y = merged[[sbt_name]]\n",
    "    x = merged[[cov]]\n",
    "    x['Intercept'] = np.ones(x.shape[0])\n",
    "\n",
    "    m = sm.OLS(y, x)\n",
    "    results = m.fit()\n",
    "\n",
    "    eff = np.sqrt(results.rsquared)\n",
    "    var = results.rsquared\n",
    "    pval = results.pvalues[cov]\n",
    "\n",
    "    patients = merged[merged.DX_GROUP==1][sbt_name]\n",
    "    controls = merged[merged.DX_GROUP==0][sbt_name]\n",
    "    pat_std = np.std(patients)\n",
    "    ctr_std = np.std(controls)\n",
    "    n_pat = len(patients)\n",
    "    n_ctr = len(controls)\n",
    "    pooled_std = np.sqrt(((n_pat-1)*np.square(pat_std) + (n_ctr-1)*np.square(ctr_std))/(n_pat + n_ctr - 2))\n",
    "\n",
    "    cohensd = np.abs((np.mean(patients) - np.mean(controls)) / pooled_std)\n",
    "\n",
    "    print('Net {} sbt {} eff: {:.3f}, var: {:.3f} p: {:.3f} cohens: {:.3f}'.format(net_id+1, sbt_id+1, eff, var, pval, cohensd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
